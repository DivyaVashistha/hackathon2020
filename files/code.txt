from pyspark import SQLContext
from pyspark.sql import SparkSession
import requests as r


spark = SparkSession \
            .builder \
            .appName("Python Spark SQL Hive integration") \
            .enableHiveSupport() \
            .getOrCreate()
sqlContext = SQLContext(self.spark)

print(spark_df.orderBy(spark_df[0],ascending=False).head(1))

spark_df=spark_df.withColumnRenamed(old_column, new_column)
